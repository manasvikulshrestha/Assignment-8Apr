{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eeec7b3f-5f98-4391-bc1d-45cceb952785",
   "metadata": {},
   "source": [
    "Q1. In order to predict house price based on several characteristics, such as location, square footage,\n",
    "number of bedrooms, etc., you are developing an SVM regression model. Which regression metric in this\n",
    "situation would be the best to employ?\n",
    "Dataset link:\n",
    "    https://drive.google.com/file/d/1Z9oLpmt6IDRNw7IeNcHYTGeJRYypRSC0/view?usp=share_link\n",
    "\n",
    "Q2. You have built an SVM regression model and are trying to decide between using MSE or R-squared as\n",
    "your evaluation metric. Which metric would be more appropriate if your goal is to predict the actual price\n",
    "of a house as accurately as possible?\n",
    "Q3. You have a dataset with a significant number of outliers and are trying to select an appropriate\n",
    "regression metric to use with your SVM model. Which metric would be the most appropriate in this\n",
    "scenario?\n",
    "Q4. You have built an SVM regression model using a polynomial kernel and are trying to select the best\n",
    "metric to evaluate its performance. You have calculated both MSE and RMSE and found that both values\n",
    "are very close. Which metric should you choose to use in this case?\n",
    "Q5. You are comparing the performance of different SVM regression models using different kernels (linear,\n",
    "polynomial, and RBF) and are trying to select the best evaluation metric. Which metric would be most\n",
    "appropriate if your goal is to measure how well the model explains the variance in the target variable?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc117e5-9432-4bb0-90a2-e9c8aaa48bef",
   "metadata": {},
   "source": [
    "### Q1: Best Regression Metric for Predicting House Prices\n",
    "\n",
    "In the context of predicting house prices based on various characteristics, the most appropriate regression metric would be the **Root Mean Squared Error (RMSE)**. RMSE is preferred because it provides a measure of the average magnitude of the errors between predicted and actual values, giving more weight to larger errors due to the squaring process. This is particularly useful when predicting house prices, as larger errors can significantly impact the assessment of model performance.\n",
    "\n",
    "### Q2: Choosing Between MSE and R-squared for Predicting House Prices\n",
    "\n",
    "If your goal is to predict the actual price of a house as accurately as possible, the **Mean Squared Error (MSE)** or **Root Mean Squared Error (RMSE)** would be more appropriate. These metrics directly measure the average magnitude of the prediction errors in units of the target variable (house prices), providing a clear indication of prediction accuracy.\n",
    "\n",
    "- **MSE** is the average of the squared differences between predicted and actual values.\n",
    "- **RMSE** is the square root of MSE and has the same units as the target variable, making it more interpretable.\n",
    "\n",
    "### Q3: Appropriate Metric for Datasets with Outliers\n",
    "\n",
    "When dealing with datasets with a significant number of outliers, **Mean Absolute Error (MAE)** would be the most appropriate metric. MAE measures the average magnitude of errors without squaring them, making it less sensitive to outliers compared to MSE or RMSE. This allows the evaluation to focus on the average error rather than being disproportionately influenced by large errors.\n",
    "\n",
    "### Q4: Choosing Between MSE and RMSE for Polynomial Kernel\n",
    "\n",
    "When both MSE and RMSE values are very close, it typically indicates that the errors are evenly distributed and neither metric will provide significantly different insights. In this case, **RMSE** is often preferred because it is on the same scale as the target variable (house prices), making it more interpretable and easier to communicate.\n",
    "\n",
    "### Q5: Evaluating Model Performance with Different Kernels\n",
    "\n",
    "To measure how well the model explains the variance in the target variable, the most appropriate metric is **R-squared (RÂ²)**. R-squared provides a proportion of the variance in the target variable that is explained by the model, allowing for a comparison of explanatory power across different models with various kernels.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16be3733-fa2e-49bb-89f1-d3c056e8534d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 18878.99963598166\n",
      "RMSE: 137.4008720350117\n",
      "MAE: 47.49359331477567\n",
      "R-squared: 0.17851072584289418\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['svr_poly_model.pkl']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Implementation Example\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import joblib\n",
    "\n",
    "# Load dataset from the given link\n",
    "data_url = 'https://drive.google.com/uc?export=download&id=1Z9oLpmt6IDRNw7IeNcHYTGeJRYypRSC0'\n",
    "data = pd.read_csv(data_url)\n",
    "\n",
    "# Assuming dataset has 'price' as target variable and rest are features\n",
    "X = data.drop('price', axis=1)\n",
    "y = data['price']\n",
    "\n",
    "# Identify numeric and categorical columns\n",
    "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_features = X.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Preprocess the data (impute missing values, scale numeric features, and encode categorical features)\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create an SVR model pipeline\n",
    "svr_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('svr', SVR(kernel='poly', degree=2, C=1.0, epsilon=0.1))\n",
    "])\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "svr_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict the target variable for the test set\n",
    "y_pred = svr_pipeline.predict(X_test)\n",
    "\n",
    "# Calculate and print evaluation metrics\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"MSE: {mse}\")\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"MAE: {mae}\")\n",
    "print(f\"R-squared: {r2}\")\n",
    "\n",
    "# Save the trained model to a file\n",
    "joblib.dump(svr_pipeline, 'svr_poly_model.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41dbbaa7-c8f8-435f-9f0f-0e430de0dd2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
